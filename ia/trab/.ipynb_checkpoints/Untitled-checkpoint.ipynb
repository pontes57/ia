{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d1ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_101 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 32, 16, 16)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 32, 16, 16)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                409650    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 481,400\n",
      "Trainable params: 464,724\n",
      "Non-trainable params: 16,676\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 1.8156 - accuracy: 0.3675 - val_loss: 1.3781 - val_accuracy: 0.4965\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 1.3347 - accuracy: 0.5224 - val_loss: 1.1766 - val_accuracy: 0.5794\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 1.1636 - accuracy: 0.5869 - val_loss: 1.0996 - val_accuracy: 0.6042\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.0501 - accuracy: 0.6316 - val_loss: 1.0256 - val_accuracy: 0.6334\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.9703 - accuracy: 0.6599 - val_loss: 0.9461 - val_accuracy: 0.6636\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.9137 - accuracy: 0.6800 - val_loss: 0.8035 - val_accuracy: 0.7122\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.8622 - accuracy: 0.6991 - val_loss: 0.7598 - val_accuracy: 0.7352\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.8270 - accuracy: 0.7115 - val_loss: 0.7977 - val_accuracy: 0.7153\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.8040 - accuracy: 0.7203 - val_loss: 0.6987 - val_accuracy: 0.7503\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.7783 - accuracy: 0.7274 - val_loss: 0.7353 - val_accuracy: 0.7378\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.7551 - accuracy: 0.7372 - val_loss: 0.6743 - val_accuracy: 0.7644\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.7447 - accuracy: 0.7387 - val_loss: 0.6567 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.7240 - accuracy: 0.7484 - val_loss: 0.6876 - val_accuracy: 0.7532\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.7095 - accuracy: 0.7523 - val_loss: 0.6449 - val_accuracy: 0.7730\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6938 - accuracy: 0.7574 - val_loss: 0.6510 - val_accuracy: 0.7714\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6870 - accuracy: 0.7615 - val_loss: 0.6460 - val_accuracy: 0.7768\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6767 - accuracy: 0.7641 - val_loss: 0.6423 - val_accuracy: 0.7764\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6710 - accuracy: 0.7645 - val_loss: 0.6526 - val_accuracy: 0.7703\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6583 - accuracy: 0.7701 - val_loss: 0.6019 - val_accuracy: 0.7885\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6499 - accuracy: 0.7727 - val_loss: 0.5974 - val_accuracy: 0.7914\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6446 - accuracy: 0.7739 - val_loss: 0.6005 - val_accuracy: 0.7930\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6345 - accuracy: 0.7786 - val_loss: 0.5921 - val_accuracy: 0.7918\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6297 - accuracy: 0.7806 - val_loss: 0.5953 - val_accuracy: 0.7940\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.6200 - accuracy: 0.7837 - val_loss: 0.6091 - val_accuracy: 0.7853\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.6140 - accuracy: 0.7858 - val_loss: 0.6004 - val_accuracy: 0.7887\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.6078 - accuracy: 0.7875 - val_loss: 0.6191 - val_accuracy: 0.7846\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.6057 - accuracy: 0.7889 - val_loss: 0.5856 - val_accuracy: 0.7934\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.5980 - accuracy: 0.7910 - val_loss: 0.5969 - val_accuracy: 0.7941\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.5985 - accuracy: 0.7902 - val_loss: 0.6173 - val_accuracy: 0.7851\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5831 - accuracy: 0.7957 - val_loss: 0.6003 - val_accuracy: 0.7937\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5822 - accuracy: 0.7981 - val_loss: 0.5651 - val_accuracy: 0.8092\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.5778 - accuracy: 0.7967 - val_loss: 0.5579 - val_accuracy: 0.8073\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5716 - accuracy: 0.7993 - val_loss: 0.5646 - val_accuracy: 0.8050\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.5748 - accuracy: 0.7974 - val_loss: 0.5651 - val_accuracy: 0.8054\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5608 - accuracy: 0.8027 - val_loss: 0.6069 - val_accuracy: 0.7942\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 25s 31ms/step - loss: 0.5578 - accuracy: 0.8041 - val_loss: 0.5800 - val_accuracy: 0.8035\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 43s 54ms/step - loss: 0.5608 - accuracy: 0.8045 - val_loss: 0.5662 - val_accuracy: 0.8077\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5545 - accuracy: 0.8034 - val_loss: 0.5669 - val_accuracy: 0.8066\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5529 - accuracy: 0.8056 - val_loss: 0.5588 - val_accuracy: 0.8068\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5514 - accuracy: 0.8061 - val_loss: 0.5900 - val_accuracy: 0.7970\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5454 - accuracy: 0.8088 - val_loss: 0.5605 - val_accuracy: 0.8069\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 24s 31ms/step - loss: 0.5442 - accuracy: 0.8094 - val_loss: 0.5714 - val_accuracy: 0.8080\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.5384 - accuracy: 0.8107 - val_loss: 0.5585 - val_accuracy: 0.8137\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.5395 - accuracy: 0.8111 - val_loss: 0.5623 - val_accuracy: 0.8093\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5328 - accuracy: 0.8115 - val_loss: 0.5559 - val_accuracy: 0.8098\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 42s 53ms/step - loss: 0.5315 - accuracy: 0.8145 - val_loss: 0.5823 - val_accuracy: 0.8014\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 27s 34ms/step - loss: 0.5333 - accuracy: 0.8133 - val_loss: 0.5675 - val_accuracy: 0.8073\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.5270 - accuracy: 0.8159 - val_loss: 0.5616 - val_accuracy: 0.8067\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.5314 - accuracy: 0.8136 - val_loss: 0.5834 - val_accuracy: 0.8035\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.5212 - accuracy: 0.8175 - val_loss: 0.5645 - val_accuracy: 0.8068\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.5180 - accuracy: 0.8179 - val_loss: 0.5533 - val_accuracy: 0.8116\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.5217 - accuracy: 0.8178 - val_loss: 0.5765 - val_accuracy: 0.8067\n",
      "Epoch 53/100\n",
      "573/782 [====================>.........] - ETA: 5s - loss: 0.5093 - accuracy: 0.8201"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.regularizers import l2\n",
    "from keras.regularizers import l1\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "# Fixando a aleatoriedade\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Carregando os dados\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#print(\"Xtrain[0] \",X_train[0])\n",
    "#print(\"Ytrain[0] \",y_train[0])\n",
    "\n",
    "\n",
    "# Normalizando as entradas para 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Codificando a saida para one hot\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "#print(\"Xtrain[0] \",X_train[0])\n",
    "#print(\"Ytrain[0] \",y_train[0])\n",
    "\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size= (3, 3), input_shape=(3, 32, 32), padding='same',\n",
    "activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=32, kernel_size= (3, 3), input_shape=(3, 32, 32), padding='same',\n",
    "activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=32, kernel_size= (3, 3), input_shape=(3, 32, 32), padding='same',\n",
    "activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=32, kernel_size= (3, 3), input_shape=(3, 16, 16), padding='same',\n",
    "activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=32, kernel_size= (3, 3), input_shape=(3, 16, 16), padding='same',\n",
    "activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compilando o modelo\n",
    "epocas = 100\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy' ]) \n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epocas, batch_size=32)\n",
    "\n",
    "# Avaliacao final do modelo\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "# Sumariza para a precis√£o\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Sumariza para a mostrar a perda\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.save('modelT1')\n",
    "\n",
    "print(\"\\nFim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad608dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
